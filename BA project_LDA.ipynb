{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# do the LDA\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import pprint\n",
    "import nltk\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BA=pd.read_csv('BA')\n",
    "df_DS=pd.read_csv('DS')\n",
    "df_DA=pd.read_csv('DA')\n",
    "df_DE=pd.read_csv('DE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = STOPWORDS.union(set(['experience', 'work','requirements','ability','years','analyst',\n",
    "                                     'required','including','best','new','applicants','jobs','candidate',\n",
    "                                     'help','regard','qualified','employment','consideration','applications',\n",
    "                                     'position','able','application','role'\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq_filter(df):\n",
    "    l1=\"\"\n",
    "    for i in df_BA.index:\n",
    "        sents=df_BA.loc[i]['JD']\n",
    "        l1+=(sents.replace('\\n',''))\n",
    "    word_tokens = word_tokenize(l1)\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    wordlist=[word for word in word_tokens if word.isalnum() and word not in stop_words]\n",
    "    full_text=\"\"\n",
    "    for word in wordlist:\n",
    "        full_text+=word+\" \"\n",
    "    allWords = nltk.tokenize.word_tokenize(full_text)\n",
    "    allWordDist = nltk.FreqDist(w.lower() for w in allWords)\n",
    "    mostCommon= allWordDist.most_common(500)\n",
    "    common_words = []\n",
    "    for item in mostCommon:\n",
    "        common_words.append(item[0])\n",
    "    leastCommon= allWordDist.most_common()[:-100-1:-1]\n",
    "    least_words = []\n",
    "    for item in leastCommon:\n",
    "        least_words.append(item[0])\n",
    "    return common_words+least_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def lda(df,num_topics = 3,passes = 30,num_words=8):\n",
    "    l1=[]\n",
    "    for i in df.index:\n",
    "        sents=df.loc[i]['JD']\n",
    "        l1.append(sents.replace('\\n',''))\n",
    "    \n",
    "    texts = [[word for word in story.lower().split()\n",
    "            if word not in my_stop_words and word not in freq_words and word.isalnum()]\n",
    "            for story in l1]\n",
    "    dictionary = corpora.Dictionary(texts) #(word_id,word) pairs\n",
    "    #dictionary.filter_extremes(no_below=20,no_above=0.2, keep_n= 100000)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    \n",
    "    lda = LdaModel(corpus,\n",
    "              id2word=dictionary,\n",
    "              num_topics=num_topics,\n",
    "              passes=passes)\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(lda.print_topics(num_words))\n",
    "    \n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.002*\"credit\" + 0.002*\"concise\" + 0.002*\"corporate\" + '\n",
      "        '0.002*\"feedback\" + 0.002*\"challenges\" + 0.002*\"asset\" + '\n",
      "        '0.002*\"physical\" + 0.002*\"mortgage\" + 0.002*\"party\" + '\n",
      "        '0.002*\"integrate\"'),\n",
      "    (   1,\n",
      "        '0.002*\"Ã¢\" + 0.002*\"preparing\" + 0.002*\"custom\" + 0.002*\"junior\" + '\n",
      "        '0.002*\"core\" + 0.002*\"maintains\" + 0.002*\"available\" + '\n",
      "        '0.002*\"exposure\" + 0.002*\"sprint\" + 0.002*\"essential\"'),\n",
      "    (   2,\n",
      "        '0.002*\"human\" + 0.002*\"texas\" + 0.002*\"pricing\" + 0.002*\"medicaid\" + '\n",
      "        '0.002*\"medical\" + 0.002*\"day\" + 0.002*\"assistance\" + '\n",
      "        '0.002*\"influence\" + 0.002*\"navision\" + 0.001*\"vendor\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('credit', 0.002144061)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_BA)\n",
    "BA_lda=lda(df_BA).show_topic(0)\n",
    "BA_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.003*\"government\" + 0.003*\"public\" + 0.003*\"medical\" + '\n",
      "        '0.002*\"clearance\" + 0.002*\"assistance\" + 0.002*\"secret\" + '\n",
      "        '0.002*\"clinical\" + 0.002*\"programming\" + 0.002*\"statistical\" + '\n",
      "        '0.002*\"dod\"'),\n",
      "    (   1,\n",
      "        '0.006*\"visualization\" + 0.005*\"bi\" + 0.005*\"power\" + '\n",
      "        '0.004*\"quantitative\" + 0.004*\"statistical\" + 0.004*\"actionable\" + '\n",
      "        '0.003*\"python\" + 0.003*\"sets\" + 0.003*\"decision\" + 0.003*\"etl\"'),\n",
      "    (   2,\n",
      "        '0.028*\"statistical\" + 0.011*\"interpret\" + 0.010*\"packages\" + '\n",
      "        '0.009*\"sources\" + 0.008*\"programming\" + 0.008*\"techniques\" + '\n",
      "        '0.007*\"collection\" + 0.006*\"sas\" + 0.006*\"statistics\" + '\n",
      "        '0.006*\"datasets\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('government', 0.0034555565),\n",
       " ('public', 0.0031454507),\n",
       " ('medical', 0.003044649),\n",
       " ('clearance', 0.002495837),\n",
       " ('assistance', 0.0022639974),\n",
       " ('secret', 0.0021883913),\n",
       " ('clinical', 0.0020776147),\n",
       " ('programming', 0.002007039),\n",
       " ('statistical', 0.0019959344),\n",
       " ('dod', 0.0019720471)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DA)\n",
    "DA_lda=lda(df_DA).show_topic(0)\n",
    "DA_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.023*\"machine\" + 0.021*\"learning\" + 0.016*\"statistical\" + '\n",
      "        '0.010*\"quantitative\" + 0.008*\"predictive\" + 0.007*\"techniques\" + '\n",
      "        '0.006*\"scientist\" + 0.006*\"deep\" + 0.006*\"algorithms\" + 0.005*\"ml\"'),\n",
      "    (   1,\n",
      "        '0.014*\"statistical\" + 0.008*\"analytic\" + 0.008*\"scientist\" + '\n",
      "        '0.005*\"visualization\" + 0.005*\"machine\" + 0.005*\"clinical\" + '\n",
      "        '0.005*\"programming\" + 0.004*\"courses\" + 0.004*\"social\" + '\n",
      "        '0.004*\"predictive\"'),\n",
      "    (   2,\n",
      "        '0.021*\"quantum\" + 0.009*\"algorithms\" + 0.006*\"qiskit\" + '\n",
      "        '0.006*\"computers\" + 0.005*\"career\" + 0.005*\"diverse\" + 0.005*\"linear\" '\n",
      "        '+ 0.005*\"looking\" + 0.005*\"employee\" + 0.005*\"optimization\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('machine', 0.023140399),\n",
       " ('learning', 0.02115203),\n",
       " ('statistical', 0.016178768),\n",
       " ('quantitative', 0.00981468),\n",
       " ('predictive', 0.0077376217),\n",
       " ('techniques', 0.007384834),\n",
       " ('scientist', 0.0061968807),\n",
       " ('deep', 0.0060998835),\n",
       " ('algorithms', 0.005533578),\n",
       " ('ml', 0.0054710247)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DS)\n",
    "DS_lda=lda(df_DS).show_topic(0)\n",
    "DS_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.007*\"pipelines\" + 0.007*\"big\" + 0.007*\"etl\" + 0.007*\"python\" + '\n",
      "        '0.006*\"machine\" + 0.006*\"learning\" + 0.005*\"engineer\" + '\n",
      "        '0.005*\"warehousing\" + 0.004*\"programming\" + 0.004*\"distributed\"'),\n",
      "    (   1,\n",
      "        '0.016*\"big\" + 0.011*\"aws\" + 0.009*\"etl\" + 0.009*\"engineer\" + '\n",
      "        '0.006*\"spark\" + 0.006*\"infrastructure\" + 0.005*\"pipeline\" + '\n",
      "        '0.005*\"python\" + 0.005*\"relational\" + 0.005*\"programming\"'),\n",
      "    (   2,\n",
      "        '0.010*\"azure\" + 0.009*\"big\" + 0.008*\"pipelines\" + 0.007*\"aws\" + '\n",
      "        '0.006*\"programming\" + 0.006*\"python\" + 0.006*\"machine\" + '\n",
      "        '0.005*\"learning\" + 0.005*\"spark\" + 0.005*\"streaming\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('pipelines', 0.0070289895),\n",
       " ('big', 0.006977768),\n",
       " ('etl', 0.0068747825),\n",
       " ('python', 0.0065189097),\n",
       " ('machine', 0.0056351507),\n",
       " ('learning', 0.005504947),\n",
       " ('engineer', 0.0050493325),\n",
       " ('warehousing', 0.004562349),\n",
       " ('programming', 0.0044694417),\n",
       " ('distributed', 0.0044409274)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DE)\n",
    "DE_lda=lda(df_DE).show_topic(0)\n",
    "DE_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LDA_List', 'w') as f:\n",
    "      \n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow(BA_lda)\n",
    "    write.writerow(DA_lda)\n",
    "    write.writerow(DS_lda)\n",
    "    write.writerow(DE_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Topic to Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "lda.get_document_topics(corpus_new[0],minimum_probability=0.05,per_word_topics=False)\n",
    "sorted(lda.get_document_topics(corpus_new[0],minimum_probability=0,per_word_topics=False),key=itemgetter(1),reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
