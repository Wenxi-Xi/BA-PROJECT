{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# do the LDA\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import pprint\n",
    "import nltk\n",
    "from nltk import sent_tokenize,word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BA=pd.read_csv('BA')\n",
    "df_DS=pd.read_csv('DS')\n",
    "df_DA=pd.read_csv('DA')\n",
    "df_DE=pd.read_csv('DE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = STOPWORDS.union(set(['experience', 'work','requirements','ability','years','analyst',\n",
    "                                     'required','including','best','new','applicants','jobs','candidate',\n",
    "                                     'help','regard','qualified','employment','consideration','applications',\n",
    "                                     'position'\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def lda(df,num_topics = 3,passes = 50,num_words=8):\n",
    "    l1=[]\n",
    "    for i in df.index:\n",
    "        sents=df.loc[i]['JD']\n",
    "        l1.append(sents.replace('\\n',''))\n",
    "    \n",
    "    texts = [[word for word in story.lower().split()\n",
    "            if word not in my_stop_words and word.isalnum()]\n",
    "            for story in l1]\n",
    "    dictionary = corpora.Dictionary(texts) #(word_id,word) pairs\n",
    "    dictionary.filter_extremes(no_below=20,no_above=0.2, keep_n= 100000)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    \n",
    "    lda = LdaModel(corpus,\n",
    "              id2word=dictionary,\n",
    "              num_topics=num_topics,\n",
    "              passes=passes)\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(lda.print_topics(num_words))\n",
    "    \n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda(df_BA).show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda(df_DA).show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda(df_DS).show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda(df_DE).show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Ver2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BA=pd.read_csv('BA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=[]\n",
    "for i in df_BA.index:\n",
    "    sents=df_BA.loc[i]['JD']\n",
    "    l1.append(sents.replace('\\n',''))\n",
    "    \n",
    "texts = [[word for word in story.lower().split()\n",
    "            if word not in STOPWORDS and word.isalnum()]\n",
    "            for story in l1]\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=20,no_above=0.2, keep_n= 100000)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.008*\"sap\" + 0.008*\"required\" + 0.007*\"applicants\" + '\n",
      "        '0.006*\"employment\" + 0.006*\"protected\" + 0.006*\"time\" + '\n",
      "        '0.005*\"qualified\" + 0.005*\"acceptance\" + 0.005*\"national\" + '\n",
      "        '0.005*\"high\"'),\n",
      "    (   1,\n",
      "        '0.010*\"reporting\" + 0.008*\"service\" + 0.008*\"required\" + '\n",
      "        '0.007*\"sales\" + 0.007*\"reports\" + 0.007*\"financial\" + '\n",
      "        '0.007*\"performance\" + 0.006*\"salesforce\" + 0.006*\"drive\" + '\n",
      "        '0.006*\"able\"'),\n",
      "    (   2,\n",
      "        '0.010*\"client\" + 0.006*\"solution\" + 0.006*\"agile\" + 0.005*\"industry\" '\n",
      "        '+ 0.005*\"best\" + 0.005*\"training\" + 0.005*\"requirement\" + '\n",
      "        '0.005*\"senior\" + 0.005*\"delivery\" + 0.004*\"current\"')]\n"
     ]
    }
   ],
   "source": [
    "lda = LdaModel(corpus,\n",
    "              id2word=dictionary,\n",
    "              num_topics=3,\n",
    "              passes=10)\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(lda.print_topics(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') \n",
    "# excluded tags\n",
    "excluded_tags = {\"VERB\", \"ADJ\", \"ADV\", \"ADP\"}\n",
    "\n",
    "l1=[]\n",
    "for i in df_BA.index:\n",
    "    sents=df_BA.loc[i]['JD']\n",
    "    l1.append(sents.split(\"\\n\"))\n",
    "\n",
    "sentences = l1[0]\n",
    "new_sentences = []\n",
    "for sentence in sentences:\n",
    "    new_sentence = []\n",
    "    for token in nlp(sentence):\n",
    "        if token.pos_ not in excluded_tags:\n",
    "            new_sentence.append(token.text)\n",
    "    new_sentences.append(\" \".join(new_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Topic to Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "lda.get_document_topics(corpus_new[0],minimum_probability=0.05,per_word_topics=False)\n",
    "sorted(lda.get_document_topics(corpus_new[0],minimum_probability=0,per_word_topics=False),key=itemgetter(1),reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
