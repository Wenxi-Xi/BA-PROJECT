{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# do the LDA\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import pprint\n",
    "import nltk\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BA=pd.read_csv('BA')\n",
    "df_DS=pd.read_csv('DS')\n",
    "df_DA=pd.read_csv('DA')\n",
    "df_DE=pd.read_csv('DE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = STOPWORDS.union(set(['experience', 'work','requirements','ability','years','analyst',\n",
    "                                     'required','including','best','new','applicants','jobs','candidate',\n",
    "                                     'help','regard','qualified','employment','consideration','applications',\n",
    "                                     'position','able','application','role'\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq_filter(df):\n",
    "    l1=\"\"\n",
    "    for i in df_BA.index:\n",
    "        sents=df_BA.loc[i]['JD']\n",
    "        l1+=(sents.replace('\\n',''))\n",
    "    word_tokens = word_tokenize(l1)\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    wordlist=[word for word in word_tokens if word.isalnum() and word not in stop_words]\n",
    "    full_text=\"\"\n",
    "    for word in newlist:\n",
    "        full_text+=word+\" \"\n",
    "    allWords = nltk.tokenize.word_tokenize(full_text)\n",
    "    allWordDist = nltk.FreqDist(w.lower() for w in allWords)\n",
    "    mostCommon= allWordDist.most_common(500)\n",
    "    common_words = []\n",
    "    for item in mostCommon:\n",
    "        common_words.append(item[0])\n",
    "    leastCommon= allWordDist.most_common()[:-100-1:-1]\n",
    "    least_words = []\n",
    "    for item in leastCommon:\n",
    "        least_words.append(item[0])\n",
    "    return common_words+least_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def lda(df,num_topics = 3,passes = 30,num_words=8):\n",
    "    l1=[]\n",
    "    for i in df.index:\n",
    "        sents=df.loc[i]['JD']\n",
    "        l1.append(sents.replace('\\n',''))\n",
    "    \n",
    "    texts = [[word for word in story.lower().split()\n",
    "            if word not in my_stop_words and word not in freq_words and word.isalnum()]\n",
    "            for story in l1]\n",
    "    dictionary = corpora.Dictionary(texts) #(word_id,word) pairs\n",
    "    #dictionary.filter_extremes(no_below=20,no_above=0.2, keep_n= 100000)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    \n",
    "    lda = LdaModel(corpus,\n",
    "              id2word=dictionary,\n",
    "              num_topics=num_topics,\n",
    "              passes=passes)\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(lda.print_topics(num_words))\n",
    "    \n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.003*\"credit\" + 0.002*\"preparing\" + 0.002*\"junior\" + 0.002*\"human\" + '\n",
      "        '0.002*\"texas\" + 0.002*\"result\" + 0.002*\"procurement\" + 0.002*\"public\" '\n",
      "        '+ 0.002*\"available\" + 0.002*\"member\"'),\n",
      "    (   1,\n",
      "        '0.002*\"input\" + 0.002*\"common\" + 0.002*\"maintains\" + 0.002*\"digital\" '\n",
      "        '+ 0.002*\"tight\" + 0.002*\"challenges\" + 0.002*\"issue\" + 0.002*\"party\" '\n",
      "        '+ 0.002*\"feedback\" + 0.002*\"integrate\"'),\n",
      "    (   2,\n",
      "        '0.002*\"Ã¢\" + 0.002*\"quantitative\" + 0.002*\"corporate\" + 0.002*\"asset\" '\n",
      "        '+ 0.002*\"applying\" + 0.002*\"influence\" + 0.002*\"primary\" + '\n",
      "        '0.002*\"relationship\" + 0.002*\"deployment\" + 0.002*\"assess\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('credit', 0.0025979741),\n",
       " ('preparing', 0.0024186007),\n",
       " ('junior', 0.0024156002),\n",
       " ('human', 0.002175819),\n",
       " ('texas', 0.0021729174),\n",
       " ('result', 0.0018748535),\n",
       " ('procurement', 0.0018687418),\n",
       " ('public', 0.0018381298),\n",
       " ('available', 0.001681165),\n",
       " ('member', 0.0016775074)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_BA)\n",
    "lda(df_BA).show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.023*\"statistical\" + 0.011*\"interpret\" + 0.010*\"packages\" + '\n",
      "        '0.008*\"etl\" + 0.008*\"programming\" + 0.008*\"sources\" + '\n",
      "        '0.007*\"techniques\" + 0.006*\"statistics\" + 0.006*\"collection\" + '\n",
      "        '0.006*\"datasets\"'),\n",
      "    (   1,\n",
      "        '0.004*\"statistical\" + 0.003*\"visualization\" + 0.003*\"bi\" + '\n",
      "        '0.003*\"power\" + 0.003*\"quantitative\" + 0.003*\"decision\" + '\n",
      "        '0.003*\"programming\" + 0.002*\"digital\" + 0.002*\"employee\" + '\n",
      "        '0.002*\"big\"'),\n",
      "    (   2,\n",
      "        '0.006*\"statistical\" + 0.004*\"clinical\" + 0.004*\"public\" + '\n",
      "        '0.004*\"quantitative\" + 0.004*\"analytic\" + 0.003*\"sources\" + '\n",
      "        '0.003*\"medical\" + 0.003*\"visualization\" + 0.003*\"findings\" + '\n",
      "        '0.002*\"ad\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('statistical', 0.023213055),\n",
       " ('interpret', 0.011414719),\n",
       " ('packages', 0.010241982),\n",
       " ('etl', 0.007967286),\n",
       " ('programming', 0.007818473),\n",
       " ('sources', 0.0075994646),\n",
       " ('techniques', 0.0071637593),\n",
       " ('statistics', 0.0064336946),\n",
       " ('collection', 0.0064160144),\n",
       " ('datasets', 0.0063665253)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DA)\n",
    "lda(df_DA).show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.015*\"statistical\" + 0.012*\"machine\" + 0.009*\"learning\" + '\n",
      "        '0.009*\"predictive\" + 0.008*\"scientist\" + 0.008*\"ml\" + '\n",
      "        '0.006*\"quantitative\" + 0.005*\"analytic\" + 0.004*\"techniques\" + '\n",
      "        '0.004*\"big\"'),\n",
      "    (   1,\n",
      "        '0.022*\"machine\" + 0.021*\"learning\" + 0.013*\"statistical\" + '\n",
      "        '0.009*\"quantitative\" + 0.007*\"techniques\" + 0.006*\"algorithms\" + '\n",
      "        '0.006*\"predictive\" + 0.006*\"scientist\" + 0.005*\"deep\" + '\n",
      "        '0.005*\"programming\"'),\n",
      "    (   2,\n",
      "        '0.020*\"quantum\" + 0.010*\"statistical\" + 0.006*\"qiskit\" + '\n",
      "        '0.005*\"computers\" + 0.005*\"visualization\" + 0.005*\"career\" + '\n",
      "        '0.005*\"looking\" + 0.005*\"algorithms\" + 0.005*\"diverse\" + '\n",
      "        '0.005*\"types\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('statistical', 0.014601265),\n",
       " ('machine', 0.012153708),\n",
       " ('learning', 0.008922601),\n",
       " ('predictive', 0.008637774),\n",
       " ('scientist', 0.0076316698),\n",
       " ('ml', 0.0075254217),\n",
       " ('quantitative', 0.005964571),\n",
       " ('analytic', 0.0050975606),\n",
       " ('techniques', 0.004485691),\n",
       " ('big', 0.0044324896)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DS)\n",
    "lda(df_DS).show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.005*\"architecture\" + 0.004*\"etl\" + 0.004*\"big\" + 0.004*\"engineer\" + '\n",
      "        '0.004*\"distributed\" + 0.004*\"aws\" + 0.003*\"pipelines\" + '\n",
      "        '0.003*\"learning\" + 0.003*\"machine\" + 0.003*\"storage\"'),\n",
      "    (   1,\n",
      "        '0.016*\"big\" + 0.011*\"aws\" + 0.010*\"python\" + 0.010*\"pipelines\" + '\n",
      "        '0.008*\"etl\" + 0.008*\"engineer\" + 0.007*\"spark\" + 0.006*\"programming\" '\n",
      "        '+ 0.005*\"relational\" + 0.005*\"infrastructure\"'),\n",
      "    (   2,\n",
      "        '0.007*\"azure\" + 0.006*\"learning\" + 0.006*\"big\" + 0.006*\"machine\" + '\n",
      "        '0.006*\"etl\" + 0.006*\"programming\" + 0.005*\"engineer\" + '\n",
      "        '0.004*\"infrastructure\" + 0.003*\"warehouse\" + 0.003*\"distributed\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('architecture', 0.004746977),\n",
       " ('etl', 0.0044347183),\n",
       " ('big', 0.0043897196),\n",
       " ('engineer', 0.0043486073),\n",
       " ('distributed', 0.0041422364),\n",
       " ('aws', 0.0035794037),\n",
       " ('pipelines', 0.0034419824),\n",
       " ('learning', 0.003070593),\n",
       " ('machine', 0.0028633),\n",
       " ('storage', 0.0027973552)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DE)\n",
    "lda(df_DE).show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Topic to Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "lda.get_document_topics(corpus_new[0],minimum_probability=0.05,per_word_topics=False)\n",
    "sorted(lda.get_document_topics(corpus_new[0],minimum_probability=0,per_word_topics=False),key=itemgetter(1),reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
