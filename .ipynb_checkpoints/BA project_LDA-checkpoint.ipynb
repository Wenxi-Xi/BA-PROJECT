{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# do the LDA\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import pprint\n",
    "import nltk\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_BA=pd.read_csv('BA')\n",
    "df_DS=pd.read_csv('DS')\n",
    "df_DA=pd.read_csv('DA')\n",
    "df_DE=pd.read_csv('DE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = STOPWORDS.union(set(['experience', 'work','requirements','ability','years','analyst',\n",
    "                                     'required','including','best','new','applicants','jobs','candidate',\n",
    "                                     'help','regard','qualified','employment','consideration','applications',\n",
    "                                     'position','able','application','role'\n",
    "                                    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq_filter(df):\n",
    "    l1=\"\"\n",
    "    for i in df_BA.index:\n",
    "        sents=df_BA.loc[i]['JD']\n",
    "        l1+=(sents.replace('\\n',''))\n",
    "    word_tokens = word_tokenize(l1)\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    wordlist=[word for word in word_tokens if word.isalnum() and word not in stop_words]\n",
    "    full_text=\"\"\n",
    "    for word in wordlist:\n",
    "        full_text+=word+\" \"\n",
    "    allWords = nltk.tokenize.word_tokenize(full_text)\n",
    "    allWordDist = nltk.FreqDist(w.lower() for w in allWords)\n",
    "    mostCommon= allWordDist.most_common(500)\n",
    "    common_words = []\n",
    "    for item in mostCommon:\n",
    "        common_words.append(item[0])\n",
    "    leastCommon= allWordDist.most_common()[:-100-1:-1]\n",
    "    least_words = []\n",
    "    for item in leastCommon:\n",
    "        least_words.append(item[0])\n",
    "    return common_words+least_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_name(df):\n",
    "    name =[x for x in globals() if globals()[x] is df][0]\n",
    "    return name\n",
    "\n",
    "def lda(df,num_topics = 3,passes = 30,num_words=8):\n",
    "    l1=[]\n",
    "    for i in df.index:\n",
    "        sents=df.loc[i]['JD']\n",
    "        l1.append(sents.replace('\\n',''))\n",
    "    \n",
    "    texts = [[word for word in story.lower().split()\n",
    "            if word not in my_stop_words and word not in freq_words and word.isalnum()]\n",
    "            for story in l1]\n",
    "    dictionary = corpora.Dictionary(texts) #(word_id,word) pairs\n",
    "    #dictionary.filter_extremes(no_below=20,no_above=0.2, keep_n= 100000)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    \n",
    "    lda = LdaModel(corpus,\n",
    "              id2word=dictionary,\n",
    "              num_topics=num_topics,\n",
    "              passes=passes)\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    pp.pprint(lda.print_topics(num_words))\n",
    "    \n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.002*\"credit\" + 0.002*\"concise\" + 0.002*\"corporate\" + '\n",
      "        '0.002*\"feedback\" + 0.002*\"challenges\" + 0.002*\"asset\" + '\n",
      "        '0.002*\"physical\" + 0.002*\"mortgage\" + 0.002*\"party\" + '\n",
      "        '0.002*\"integrate\"'),\n",
      "    (   1,\n",
      "        '0.002*\"Ã¢\" + 0.002*\"preparing\" + 0.002*\"custom\" + 0.002*\"junior\" + '\n",
      "        '0.002*\"core\" + 0.002*\"maintains\" + 0.002*\"available\" + '\n",
      "        '0.002*\"exposure\" + 0.002*\"sprint\" + 0.002*\"essential\"'),\n",
      "    (   2,\n",
      "        '0.002*\"human\" + 0.002*\"texas\" + 0.002*\"pricing\" + 0.002*\"medicaid\" + '\n",
      "        '0.002*\"medical\" + 0.002*\"day\" + 0.002*\"assistance\" + '\n",
      "        '0.002*\"influence\" + 0.002*\"navision\" + 0.001*\"vendor\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('credit', 0.002144061)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_BA)\n",
    "BA_lda=lda(df_BA).show_topic(0)\n",
    "BA_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.003*\"quantitative\" + 0.003*\"analytic\" + 0.003*\"power\" + '\n",
      "        '0.003*\"medical\" + 0.002*\"visualization\" + 0.002*\"bi\" + 0.002*\"ad\" + '\n",
      "        '0.002*\"digital\" + 0.002*\"paid\" + 0.002*\"sets\"'),\n",
      "    (   1,\n",
      "        '0.021*\"statistical\" + 0.009*\"interpret\" + 0.008*\"packages\" + '\n",
      "        '0.008*\"sources\" + 0.007*\"etl\" + 0.007*\"techniques\" + '\n",
      "        '0.007*\"programming\" + 0.006*\"bi\" + 0.005*\"datasets\" + '\n",
      "        '0.005*\"statistics\"'),\n",
      "    (   2,\n",
      "        '0.006*\"statistical\" + 0.004*\"clinical\" + 0.003*\"quantitative\" + '\n",
      "        '0.003*\"public\" + 0.003*\"visualization\" + 0.003*\"sources\" + '\n",
      "        '0.003*\"analytic\" + 0.003*\"programming\" + 0.002*\"evaluation\" + '\n",
      "        '0.002*\"employee\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('quantitative', 0.0029192201),\n",
       " ('analytic', 0.002582666),\n",
       " ('power', 0.0025672012),\n",
       " ('medical', 0.0025372605),\n",
       " ('visualization', 0.0023865846),\n",
       " ('bi', 0.0023516295),\n",
       " ('ad', 0.0022938624),\n",
       " ('digital', 0.0020825127),\n",
       " ('paid', 0.0020721192),\n",
       " ('sets', 0.002037219)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DA)\n",
    "DA_lda=lda(df_DA).show_topic(0)\n",
    "DA_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.018*\"quantum\" + 0.011*\"machine\" + 0.010*\"ml\" + 0.008*\"learning\" + '\n",
      "        '0.006*\"algorithms\" + 0.005*\"diverse\" + 0.005*\"qiskit\" + '\n",
      "        '0.005*\"computers\" + 0.005*\"looking\" + 0.004*\"natural\"'),\n",
      "    (   1,\n",
      "        '0.022*\"machine\" + 0.021*\"learning\" + 0.016*\"statistical\" + '\n",
      "        '0.009*\"quantitative\" + 0.007*\"techniques\" + 0.007*\"predictive\" + '\n",
      "        '0.007*\"algorithms\" + 0.006*\"programming\" + 0.006*\"big\" + '\n",
      "        '0.006*\"python\"'),\n",
      "    (   2,\n",
      "        '0.017*\"statistical\" + 0.010*\"analytic\" + 0.007*\"scientist\" + '\n",
      "        '0.006*\"machine\" + 0.006*\"techniques\" + 0.005*\"sources\" + '\n",
      "        '0.005*\"visualization\" + 0.004*\"clinical\" + 0.004*\"learning\" + '\n",
      "        '0.004*\"programming\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('quantum', 0.017677797),\n",
       " ('machine', 0.011216796),\n",
       " ('ml', 0.009750406),\n",
       " ('learning', 0.0077902162),\n",
       " ('algorithms', 0.0060242736),\n",
       " ('diverse', 0.0051248088),\n",
       " ('qiskit', 0.005024482),\n",
       " ('computers', 0.0046378705),\n",
       " ('looking', 0.004583131),\n",
       " ('natural', 0.0044884305)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DS)\n",
    "DS_lda=lda(df_DS).show_topic(0)\n",
    "DS_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   (   0,\n",
      "        '0.013*\"big\" + 0.006*\"etl\" + 0.005*\"engineer\" + 0.005*\"warehouse\" + '\n",
      "        '0.005*\"python\" + 0.004*\"pipelines\" + 0.004*\"bull\" + 0.004*\"streaming\" '\n",
      "        '+ 0.004*\"aws\" + 0.004*\"programming\"'),\n",
      "    (   1,\n",
      "        '0.012*\"aws\" + 0.009*\"python\" + 0.008*\"pipelines\" + 0.008*\"etl\" + '\n",
      "        '0.007*\"big\" + 0.006*\"engineer\" + 0.006*\"programming\" + 0.005*\"spark\" '\n",
      "        '+ 0.004*\"apache\" + 0.004*\"distributed\"'),\n",
      "    (   2,\n",
      "        '0.012*\"big\" + 0.009*\"azure\" + 0.008*\"machine\" + 0.007*\"learning\" + '\n",
      "        '0.007*\"engineer\" + 0.007*\"infrastructure\" + 0.006*\"etl\" + '\n",
      "        '0.006*\"pipelines\" + 0.005*\"programming\" + 0.005*\"spark\"')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('big', 0.013139406),\n",
       " ('etl', 0.006475453),\n",
       " ('engineer', 0.004845691),\n",
       " ('warehouse', 0.0047575575),\n",
       " ('python', 0.004501147),\n",
       " ('pipelines', 0.004488647),\n",
       " ('bull', 0.004450075),\n",
       " ('streaming', 0.0040275455),\n",
       " ('aws', 0.003955949),\n",
       " ('programming', 0.0037249345)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_words=word_freq_filter(df_DE)\n",
    "DE_lda=lda(df_DE).show_topic(0)\n",
    "DE_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('LDA_List', 'w') as f:\n",
    "      \n",
    "    # using csv.writer method from CSV package\n",
    "    write = csv.writer(f)\n",
    "      \n",
    "    write.writerow(BA_lda)\n",
    "    write.writerow(DA_lda)\n",
    "    write.writerow(DS_lda)\n",
    "    write.writerow(DE_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Topic to Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "lda.get_document_topics(corpus_new[0],minimum_probability=0.05,per_word_topics=False)\n",
    "sorted(lda.get_document_topics(corpus_new[0],minimum_probability=0,per_word_topics=False),key=itemgetter(1),reverse=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
